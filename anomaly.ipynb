{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Un4cRK4rc7k7-9mCWmdn_HiT_WVvgQJ0",
      "authorship_tag": "ABX9TyPtcgLVXrgwXpfpKuj6Yy20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahsan6159595/ahsan6159595/blob/main/anomaly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-hub==0.14.1 transformers==4.29.2 torch==2.0.1 numpy==1.25.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7scffY1t3o-_",
        "outputId": "5066ecf5-5cdc-4b30-e921-2ad0522425fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface-hub==0.14.1\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting transformers==4.29.2\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl.metadata (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting numpy==1.25.2\n",
            "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (3.15.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (4.66.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (4.12.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.2) (2024.5.15)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.1)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.14.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.14.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.14.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.14.1) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, transformers, triton, torch\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xgboost 2.1.0 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.25.2 which is incompatible.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.14.1 lit-18.1.8 numpy-1.25.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 tokenizers-0.13.3 torch-2.0.1 transformers-4.29.2 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d3a4be98a3e2415f904a066419b798b1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/moment-timeseries-foundation-model/moment.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0thkchT4Xbz",
        "outputId": "a948c9e5-8a06-4845-e20a-d19595f398ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/moment-timeseries-foundation-model/moment.git\n",
            "  Cloning https://github.com/moment-timeseries-foundation-model/moment.git to /tmp/pip-req-build-j0448ad8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/moment-timeseries-foundation-model/moment.git /tmp/pip-req-build-j0448ad8\n",
            "  Resolved https://github.com/moment-timeseries-foundation-model/moment.git to commit aad59148bf4b9f43d144c2aed72324cfed45dffe\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub==0.19.4 (from momentfm==0.1)\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy==1.25.2 in /usr/local/lib/python3.10/dist-packages (from momentfm==0.1) (1.25.2)\n",
            "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.10/dist-packages (from momentfm==0.1) (2.0.1)\n",
            "Collecting transformers==4.33.3 (from momentfm==0.1)\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl.metadata (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.19.4->momentfm==0.1) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.19.4->momentfm==0.1) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.19.4->momentfm==0.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.19.4->momentfm==0.1) (4.66.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.19.4->momentfm==0.1) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.19.4->momentfm==0.1) (4.12.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.19.4->momentfm==0.1) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.3->momentfm==0.1) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.3->momentfm==0.1) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.3->momentfm==0.1) (0.4.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->momentfm==0.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch~=2.0->momentfm==0.1) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch~=2.0->momentfm==0.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch~=2.0->momentfm==0.1) (3.30.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch~=2.0->momentfm==0.1) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.0->momentfm==0.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.19.4->momentfm==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.19.4->momentfm==0.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.19.4->momentfm==0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.19.4->momentfm==0.1) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.0->momentfm==0.1) (1.3.0)\n",
            "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: momentfm\n",
            "  Building wheel for momentfm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for momentfm: filename=momentfm-0.1-py3-none-any.whl size=33192 sha256=c5bdd143ea533bfb5c41ebcef269d383d7d2550ea9f41b52c6320e1f7d5699c8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2h3v333k/wheels/6e/62/da/a5752a90276fbaebe0da5c0d02272f6549f43e9ceaac72907e\n",
            "Successfully built momentfm\n",
            "Installing collected packages: huggingface-hub, transformers, momentfm\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.14.1\n",
            "    Uninstalling huggingface-hub-0.14.1:\n",
            "      Successfully uninstalled huggingface-hub-0.14.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.29.2\n",
            "    Uninstalling transformers-4.29.2:\n",
            "      Successfully uninstalled transformers-4.29.2\n",
            "Successfully installed huggingface-hub-0.19.4 momentfm-0.1 transformers-4.33.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface-hub transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPjTCnWp40DD",
        "outputId": "ce8fc6ff-9b13-48ef-c350-4ad664f19fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.7.4)\n",
            "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.33.3\n",
            "    Uninstalling transformers-4.33.3:\n",
            "      Successfully uninstalled transformers-4.33.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "momentfm 0.1 requires huggingface-hub==0.19.4, but you have huggingface-hub 0.24.5 which is incompatible.\n",
            "momentfm 0.1 requires transformers==4.33.3, but you have transformers 4.43.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.24.5 tokenizers-0.19.1 transformers-4.43.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import momentfm.utils.anomaly_detection_metrics as metrics\n",
        "dir(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0EIHOfx68vN",
        "outputId": "ec4b44e0-8a2c-4e8b-930a-075d8f40f21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'adjbestf1',\n",
              " 'adjust_predicts',\n",
              " 'f1_score',\n",
              " 'np']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show momentfm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcrKXz4_7c6C",
        "outputId": "d22c10dc-6463-41d0-e857-b75020d68138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: momentfm\n",
            "Version: 0.1\n",
            "Summary: MOMENT: A Family of Open Time Series Foundation Models\n",
            "Home-page: https://moment-timeseries-foundation-model.github.io/\n",
            "Author: Konrad Szafer, Arjun Choudhry, Yifu Cai\n",
            "Author-email: Mononito Goswami <mononitog@hotmail.com>\n",
            "License: MIT License\n",
            "        \n",
            "        Copyright (c) 2024 Auton Lab, Carnegie Mellon University\n",
            "        \n",
            "        Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "        of this software and associated documentation files (the \"Software\"), to deal\n",
            "        in the Software without restriction, including without limitation the rights\n",
            "        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "        copies of the Software, and to permit persons to whom the Software is\n",
            "        furnished to do so, subject to the following conditions:\n",
            "        \n",
            "        The above copyright notice and this permission notice shall be included in all\n",
            "        copies or substantial portions of the Software.\n",
            "        \n",
            "        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "        SOFTWARE.\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub, numpy, torch, transformers\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from momentfm.utils.anomaly_detection_metrics import adjbestf1\n",
        "\n",
        "# If adjbests is not available, check and import other available functions\n"
      ],
      "metadata": {
        "id": "Yy9ILp018GPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Verify Available Functions\n",
        "import momentfm.utils.anomaly_detection_metrics as metrics\n",
        "print(dir(metrics))\n",
        "\n",
        "# Step 2: Check Installation and Version\n",
        "!pip show momentfm\n",
        "\n",
        "# Step 3: Import Correct Functions\n",
        "# Uncomment the correct function names if found in step 1\n",
        "from momentfm.utils.anomaly_detection_metrics import adjbestf1\n",
        "# from momentfm.utils.anomaly_detection_metrics import adjbests  # Uncomment if adjbests is confirmed to be available\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-piV-dHy8N1P",
        "outputId": "c80724b5-24fb-479a-b3af-307fae995aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'adjbestf1', 'adjust_predicts', 'f1_score', 'np']\n",
            "Name: momentfm\n",
            "Version: 0.1\n",
            "Summary: MOMENT: A Family of Open Time Series Foundation Models\n",
            "Home-page: https://moment-timeseries-foundation-model.github.io/\n",
            "Author: Konrad Szafer, Arjun Choudhry, Yifu Cai\n",
            "Author-email: Mononito Goswami <mononitog@hotmail.com>\n",
            "License: MIT License\n",
            "        \n",
            "        Copyright (c) 2024 Auton Lab, Carnegie Mellon University\n",
            "        \n",
            "        Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "        of this software and associated documentation files (the \"Software\"), to deal\n",
            "        in the Software without restriction, including without limitation the rights\n",
            "        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "        copies of the Software, and to permit persons to whom the Software is\n",
            "        furnished to do so, subject to the following conditions:\n",
            "        \n",
            "        The above copyright notice and this permission notice shall be included in all\n",
            "        copies or substantial portions of the Software.\n",
            "        \n",
            "        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "        SOFTWARE.\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub, numpy, torch, transformers\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "from momentfm import MOMENTPipeline\n"
      ],
      "metadata": {
        "id": "fXf-117J8Y3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the zip file path and the extraction directory\n",
        "zip_file_path = '/content/SWaT.A7_June 2020-20240804T155146Z-001.zip'\n",
        "extract_dir = '/content/SWaT_data'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "if not os.path.exists(extract_dir):\n",
        "    os.makedirs(extract_dir)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"Extraction completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5fiu4tgIZ-B",
        "outputId": "a1db7bb0-1287-485e-a55f-f43a2284c929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List files in the extracted directory\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7Xf7Qb3IfXH",
        "outputId": "36f90f4b-fd86-44ed-c852-f66bdf8de6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SWaT_data/SWaT.A7_June 2020/29June2020 (1).xlsx\n",
            "/content/SWaT_data/SWaT.A7_June 2020/29June2020 (2).xlsx\n",
            "/content/SWaT_data/SWaT.A7_June 2020/22June2020 (1).xlsx\n",
            "/content/SWaT_data/SWaT.A7_June 2020/22June2020 (2).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to the folder containing subfolders with CSV files\n",
        "folder_path = '/content/SWaT_data'\n",
        "\n",
        "# Create a dictionary to store the dataframes\n",
        "dataframes = {}\n",
        "\n",
        "# Traverse through all subdirectories and files\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.csv'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            df_name = os.path.splitext(file)[0]  # Use the file name without extension as the key\n",
        "            dataframes[df_name] = pd.read_csv(file_path)\n",
        "            print(f\"Loaded {file} into dataframe '{df_name}'\")\n",
        "\n",
        "# Display the first few rows of each dataframe\n",
        "for df_name, df in dataframes.items():\n",
        "    print(f\"\\nDataframe: {df_name}\")\n",
        "    print(df.head())\n"
      ],
      "metadata": {
        "id": "h4LzgtpVI7ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Load all Excel files from the specified directory\n",
        "folder_path = '/content/SWaT_data/SWaT.A7_June 2020'\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(folder_path):\n",
        "    raise FileNotFoundError(f\"The folder path {folder_path} does not exist\")\n",
        "\n",
        "# Create a list to hold all dataframes\n",
        "dataframes = []\n",
        "\n",
        "# Traverse through all subdirectories and files\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.xlsx') or file.endswith('.xls'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            print(f\"Loading file: {file_path}\")\n",
        "            df = pd.read_excel(file_path)\n",
        "            dataframes.append(df)\n",
        "\n",
        "# Check if any dataframes were loaded\n",
        "if not dataframes:\n",
        "    raise ValueError(\"No Excel files found in the specified directory\")\n",
        "\n",
        "# Concatenate all dataframes\n",
        "data = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Display the first few rows of the combined dataset\n",
        "print(data.head())\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Drop non-numeric and unnecessary columns\n",
        "columns_to_drop = ['Timestamp', 'Annotation', 'Other Anomalies', 'Attack Type', 'Intent',\n",
        "                   'Attack Mode', 'Attack Outcome', 'Target Selection', 'Entry Point',\n",
        "                   'ASD', 'Attacker', 'Attack Id', 'Attack Subid']\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Fill missing values with 0\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Drop any remaining non-numeric columns\n",
        "data = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Convert back to DataFrame for easier manipulation\n",
        "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
        "\n",
        "# Step 3: Define a PyTorch Dataset class\n",
        "class SWaTDataset(Dataset):\n",
        "    def __init__(self, data, seq_len=50):\n",
        "        self.data = torch.tensor(data.values, dtype=torch.float32)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx:idx+self.seq_len]\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "seq_len = 50\n",
        "dataset = SWaTDataset(data_scaled, seq_len)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Determine the input dimension\n",
        "input_dim = data_scaled.shape[1] * seq_len\n",
        "\n",
        "# Step 4: Define the Autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model = Autoencoder(input_dim)\n",
        "\n",
        "# Set up training parameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs in tqdm(dataloader):\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
        "\n",
        "# Step 5: Anomaly Detection\n",
        "# For demonstration, we'll use the same data as test data\n",
        "test_data = data_scaled\n",
        "\n",
        "test_dataset = SWaTDataset(test_data, seq_len)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "anomalies = []\n",
        "with torch.no_grad():\n",
        "    for inputs in tqdm(test_dataloader):\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        anomalies.append(loss.item())\n",
        "\n",
        "# Convert anomalies to numpy array\n",
        "anomalies = np.array(anomalies)\n",
        "\n",
        "# Plot anomalies\n",
        "plt.plot(anomalies)\n",
        "plt.title('Anomalies')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Anomaly Score')\n",
        "plt.show()\n",
        "\n",
        "# Calculate anomaly threshold and print adjusted best F1 score (if applicable)\n",
        "threshold = np.mean(anomalies) + 3*np.std(anomalies)  # Example threshold\n",
        "anomaly_labels = anomalies > threshold\n",
        "print(f\"Anomalies detected: {np.sum(anomaly_labels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ECSjneWKRIs",
        "outputId": "f0475c03-5f4f-418c-fd32-cb6d9691aa47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/29June2020 (1).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/29June2020 (2).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/22June2020 (1).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/22June2020 (2).xlsx\n",
            "            t_stamp P1_STATE   LIT101.Pv FIT101.Pv MV101.Status P101.Status  \\\n",
            "0  6/29/20 10:00:00        3  531.168335       0.0            1           2   \n",
            "1  6/29/20 10:00:01        3  530.422546       0.0            1           2   \n",
            "2  6/29/20 10:00:02        3  530.304749       0.0            1           2   \n",
            "3  6/29/20 10:00:03        3     529.402       0.0            1           2   \n",
            "4  6/29/20 10:00:04        3    529.5197       0.0            1           2   \n",
            "\n",
            "  P102.Status P2_STATE FIT201.Pv  AIT201.Pv  ... LS401.Alarm PSH501.Alarm  \\\n",
            "0           1        2  2.344408   72.86593  ...         NaN          NaN   \n",
            "1           1        2  2.344408   72.86593  ...         NaN          NaN   \n",
            "2           1        2  2.344408  72.930016  ...         NaN          NaN   \n",
            "3           1        2  2.344408  72.930016  ...         NaN          NaN   \n",
            "4           1        2  2.345433  73.026146  ...         NaN          NaN   \n",
            "\n",
            "  PSL501.Alarm P603.Status LSH601.Alarm LSL601.Alarm LSH602.Alarm  \\\n",
            "0          NaN         NaN          NaN          NaN          NaN   \n",
            "1          NaN         NaN          NaN          NaN          NaN   \n",
            "2          NaN         NaN          NaN          NaN          NaN   \n",
            "3          NaN         NaN          NaN          NaN          NaN   \n",
            "4          NaN         NaN          NaN          NaN          NaN   \n",
            "\n",
            "  LSL602.Alarm LSH603.Alarm LSL603.Alarm  \n",
            "0          NaN          NaN          NaN  \n",
            "1          NaN          NaN          NaN  \n",
            "2          NaN          NaN          NaN  \n",
            "3          NaN          NaN          NaN  \n",
            "4          NaN          NaN          NaN  \n",
            "\n",
            "[5 rows x 16403 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Load all Excel files from the specified directory\n",
        "folder_path = '/content/SWaT_data/SWaT.A7_June 2020'\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(folder_path):\n",
        "    raise FileNotFoundError(f\"The folder path {folder_path} does not exist\")\n",
        "\n",
        "# Create a list to hold all dataframes\n",
        "dataframes = []\n",
        "\n",
        "# Traverse through all subdirectories and files\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.xlsx') or file.endswith('.xls'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            print(f\"Loading file: {file_path}\")\n",
        "            df = pd.read_excel(file_path)\n",
        "            dataframes.append(df)\n",
        "\n",
        "# Check if any dataframes were loaded\n",
        "if not dataframes:\n",
        "    raise ValueError(\"No Excel files found in the specified directory\")\n",
        "\n",
        "# Concatenate all dataframes\n",
        "data = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Display the first few rows of the combined dataset\n",
        "print(data.head())\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Drop non-numeric and unnecessary columns\n",
        "columns_to_drop = ['t_stamp']  # Include any other columns you want to drop\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Fill missing values with 0\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Drop any remaining non-numeric columns\n",
        "data = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Convert back to DataFrame for easier manipulation\n",
        "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
        "\n",
        "# Step 3: Define a PyTorch Dataset class\n",
        "class SWaTDataset(Dataset):\n",
        "    def __init__(self, data, seq_len=50):\n",
        "        self.data = torch.tensor(data.values, dtype=torch.float32)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx:idx+self.seq_len]\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "seq_len = 50\n",
        "dataset = SWaTDataset(data_scaled, seq_len)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Determine the input dimension\n",
        "input_dim = data_scaled.shape[1] * seq_len\n",
        "\n",
        "# Step 4: Define the Autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model = Autoencoder(input_dim)\n",
        "\n",
        "# Set up training parameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs in tqdm(dataloader):\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
        "\n",
        "# Step 5: Anomaly Detection\n",
        "# For demonstration, we'll use the same data as test data\n",
        "test_data = data_scaled\n",
        "\n",
        "test_dataset = SWaTDataset(test_data, seq_len)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "anomalies = []\n",
        "with torch.no_grad():\n",
        "    for inputs in tqdm(test_dataloader):\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        anomalies.extend(loss.item() for _ in range(inputs.size(0)))  # Extend list with loss values\n",
        "\n",
        "# Convert anomalies to numpy array\n",
        "anomalies = np.array(anomalies)\n",
        "\n",
        "# Plot anomalies\n",
        "plt.plot(anomalies)\n",
        "plt.title('Anomalies')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Anomaly Score')\n",
        "plt.show()\n",
        "\n",
        "# Calculate anomaly threshold and print adjusted best F1 score (if applicable)\n",
        "threshold = np.mean(anomalies) + 3 * np.std(anomalies)  # Example threshold\n",
        "anomaly_labels = anomalies > threshold\n",
        "print(f\"Anomalies detected: {np.sum(anomaly_labels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLkiw5oAOsg9",
        "outputId": "219a13fc-a41d-46dd-ab8c-0d626e61c9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/29June2020 (1).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/29June2020 (2).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/22June2020 (1).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/22June2020 (2).xlsx\n",
            "            t_stamp P1_STATE   LIT101.Pv FIT101.Pv MV101.Status P101.Status  \\\n",
            "0  6/29/20 10:00:00        3  531.168335       0.0            1           2   \n",
            "1  6/29/20 10:00:01        3  530.422546       0.0            1           2   \n",
            "2  6/29/20 10:00:02        3  530.304749       0.0            1           2   \n",
            "3  6/29/20 10:00:03        3     529.402       0.0            1           2   \n",
            "4  6/29/20 10:00:04        3    529.5197       0.0            1           2   \n",
            "\n",
            "  P102.Status P2_STATE FIT201.Pv  AIT201.Pv  ... LS401.Alarm PSH501.Alarm  \\\n",
            "0           1        2  2.344408   72.86593  ...         NaN          NaN   \n",
            "1           1        2  2.344408   72.86593  ...         NaN          NaN   \n",
            "2           1        2  2.344408  72.930016  ...         NaN          NaN   \n",
            "3           1        2  2.344408  72.930016  ...         NaN          NaN   \n",
            "4           1        2  2.345433  73.026146  ...         NaN          NaN   \n",
            "\n",
            "  PSL501.Alarm P603.Status LSH601.Alarm LSL601.Alarm LSH602.Alarm  \\\n",
            "0          NaN         NaN          NaN          NaN          NaN   \n",
            "1          NaN         NaN          NaN          NaN          NaN   \n",
            "2          NaN         NaN          NaN          NaN          NaN   \n",
            "3          NaN         NaN          NaN          NaN          NaN   \n",
            "4          NaN         NaN          NaN          NaN          NaN   \n",
            "\n",
            "  LSL602.Alarm LSH603.Alarm LSL603.Alarm  \n",
            "0          NaN          NaN          NaN  \n",
            "1          NaN          NaN          NaN  \n",
            "2          NaN          NaN          NaN  \n",
            "3          NaN          NaN          NaN  \n",
            "4          NaN          NaN          NaN  \n",
            "\n",
            "[5 rows x 16403 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Load all Excel files from the specified directory\n",
        "folder_path = '/content/SWaT_data/SWaT.A7_June 2020'\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(folder_path):\n",
        "    raise FileNotFoundError(f\"The folder path {folder_path} does not exist\")\n",
        "\n",
        "# Create a list to hold all dataframes\n",
        "dataframes = []\n",
        "\n",
        "# Traverse through all subdirectories and files\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.xlsx') or file.endswith('.xls'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            print(f\"Loading file: {file_path}\")\n",
        "            df = pd.read_excel(file_path)\n",
        "            dataframes.append(df)\n",
        "\n",
        "# Check if any dataframes were loaded\n",
        "if not dataframes:\n",
        "    raise ValueError(\"No Excel files found in the specified directory\")\n",
        "\n",
        "# Concatenate all dataframes\n",
        "data = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Display the first few rows of the combined dataset\n",
        "print(data.head())\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Drop non-numeric and unnecessary columns\n",
        "columns_to_drop = ['t_stamp']  # Include any other columns you want to drop\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Fill missing values with 0\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Drop any remaining non-numeric columns\n",
        "data = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Convert back to DataFrame for easier manipulation\n",
        "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
        "\n",
        "# Step 3: Define a PyTorch Dataset class\n",
        "class SWaTDataset(Dataset):\n",
        "    def __init__(self, data, seq_len=50):\n",
        "        self.data = torch.tensor(data.values, dtype=torch.float32)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx:idx+self.seq_len]\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "seq_len = 50\n",
        "dataset = SWaTDataset(data_scaled, seq_len)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Determine the input dimension\n",
        "input_dim = data_scaled.shape[1] * seq_len\n",
        "\n",
        "# Step 4: Define the Autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model = Autoencoder(input_dim)\n",
        "\n",
        "# Set up training parameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs in tqdm(dataloader):\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
        "\n",
        "# Step 5: Anomaly Detection\n",
        "# For demonstration, we'll use the same data as test data\n",
        "test_data = data_scaled\n",
        "\n",
        "test_dataset = SWaTDataset(test_data, seq_len)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "anomalies = []\n",
        "with torch.no_grad():\n",
        "    for inputs in tqdm(test_dataloader):\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        anomalies.extend([loss.item()] * inputs.size(0))  # Extend list with loss values\n",
        "\n",
        "# Convert anomalies to numpy array\n",
        "anomalies = np.array(anomalies)\n",
        "\n",
        "# Plot anomalies\n",
        "plt.plot(anomalies)\n",
        "plt.title('Anomalies')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Anomaly Score')\n",
        "plt.show()\n",
        "\n",
        "# Calculate anomaly threshold and print adjusted best F1 score (if applicable)\n",
        "threshold = np.mean(anomalies) + 3 * np.std(anomalies)  # Example threshold\n",
        "anomaly_labels = anomalies > threshold\n",
        "print(f\"Anomalies detected: {np.sum(anomaly_labels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnZ7AuvLQJ42",
        "outputId": "4235c9ec-3c09-475e-aad1-ee8b5b1ba36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/29June2020 (1).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/29June2020 (2).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/22June2020 (1).xlsx\n",
            "Loading file: /content/SWaT_data/SWaT.A7_June 2020/22June2020 (2).xlsx\n",
            "            t_stamp P1_STATE   LIT101.Pv FIT101.Pv MV101.Status P101.Status  \\\n",
            "0  6/29/20 10:00:00        3  531.168335       0.0            1           2   \n",
            "1  6/29/20 10:00:01        3  530.422546       0.0            1           2   \n",
            "2  6/29/20 10:00:02        3  530.304749       0.0            1           2   \n",
            "3  6/29/20 10:00:03        3     529.402       0.0            1           2   \n",
            "4  6/29/20 10:00:04        3    529.5197       0.0            1           2   \n",
            "\n",
            "  P102.Status P2_STATE FIT201.Pv  AIT201.Pv  ... LS401.Alarm PSH501.Alarm  \\\n",
            "0           1        2  2.344408   72.86593  ...         NaN          NaN   \n",
            "1           1        2  2.344408   72.86593  ...         NaN          NaN   \n",
            "2           1        2  2.344408  72.930016  ...         NaN          NaN   \n",
            "3           1        2  2.344408  72.930016  ...         NaN          NaN   \n",
            "4           1        2  2.345433  73.026146  ...         NaN          NaN   \n",
            "\n",
            "  PSL501.Alarm P603.Status LSH601.Alarm LSL601.Alarm LSH602.Alarm  \\\n",
            "0          NaN         NaN          NaN          NaN          NaN   \n",
            "1          NaN         NaN          NaN          NaN          NaN   \n",
            "2          NaN         NaN          NaN          NaN          NaN   \n",
            "3          NaN         NaN          NaN          NaN          NaN   \n",
            "4          NaN         NaN          NaN          NaN          NaN   \n",
            "\n",
            "  LSL602.Alarm LSH603.Alarm LSL603.Alarm  \n",
            "0          NaN          NaN          NaN  \n",
            "1          NaN          NaN          NaN  \n",
            "2          NaN          NaN          NaN  \n",
            "3          NaN          NaN          NaN  \n",
            "4          NaN          NaN          NaN  \n",
            "\n",
            "[5 rows x 16403 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Load the specific Excel file\n",
        "file_path = '/content/SWaT_data/SWaT.A7_June 2020/22June2020 (1).xlsx'\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"The file path {file_path} does not exist\")\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Drop non-numeric and unnecessary columns\n",
        "columns_to_drop = ['t_stamp']  # Include any other columns you want to drop\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Fill missing values with 0\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Drop any remaining non-numeric columns\n",
        "data = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Convert back to DataFrame for easier manipulation\n",
        "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
        "\n",
        "# Step 3: Define a PyTorch Dataset class\n",
        "class SWaTDataset(Dataset):\n",
        "    def __init__(self, data, seq_len=50):\n",
        "        self.data = torch.tensor(data.values, dtype=torch.float32)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx:idx+self.seq_len]\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "seq_len = 50\n",
        "dataset = SWaTDataset(data_scaled, seq_len)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Determine the input dimension\n",
        "input_dim = data_scaled.shape[1] * seq_len\n",
        "\n",
        "# Step 4: Define the Autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model = Autoencoder(input_dim)\n",
        "\n",
        "# Set up training parameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs in tqdm(dataloader):\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
        "\n",
        "# Step 5: Anomaly Detection\n",
        "# For demonstration, we'll use the same data as test data\n",
        "test_data = data_scaled\n",
        "\n",
        "test_dataset = SWaTDataset(test_data, seq_len)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "anomalies = []\n",
        "with torch.no_grad():\n",
        "    for inputs in tqdm(test_dataloader):\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten input\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        anomalies.extend([loss.item()] * inputs.size(0))  # Extend list with loss values\n",
        "\n",
        "# Convert anomalies to numpy array\n",
        "anomalies = np.array(anomalies)\n",
        "\n",
        "# Plot anomalies\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(anomalies)\n",
        "plt.title('Anomalies')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Anomaly Score')\n",
        "plt.show()\n",
        "\n",
        "# Calculate anomaly threshold and print the number of detected anomalies\n",
        "threshold = np.mean(anomalies) + 3 * np.std(anomalies)  # Example threshold\n",
        "anomaly_labels = anomalies > threshold\n",
        "print(f\"Anomalies detected: {np.sum(anomaly_labels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "51_GI1WTQYWi",
        "outputId": "4caa9975-769e-4085-ab02-87e8e85a13e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  t_stamp  P1_STATE   LIT101.Pv  FIT101.Pv  MV101.Status  \\\n",
            "0 2020-06-22 10:00:00.000         3  695.284100        0.0             1   \n",
            "1 2020-06-22 10:00:01.000         3  695.127100        0.0             1   \n",
            "2 2020-06-22 10:00:02.005         3  694.930847        0.0             1   \n",
            "3 2020-06-22 10:00:03.010         3  694.930847        0.0             1   \n",
            "4 2020-06-22 10:00:04.015         3  694.852300        0.0             1   \n",
            "\n",
            "   P101.Status  P102.Status  P2_STATE  FIT201.Pv  AIT201.Pv  ...  FIT601.Pv  \\\n",
            "0            1            1         2   0.000256  18.072288  ...   0.000256   \n",
            "1            1            1         2   0.000256  18.104332  ...   0.000256   \n",
            "2            1            1         2   0.000256  18.104332  ...   0.000256   \n",
            "3            1            1         2   0.000256  18.104332  ...   0.000256   \n",
            "4            1            1         2   0.000256  18.104332  ...   0.000256   \n",
            "\n",
            "   P601.Status  P602.Status  P603.Status  LSH601.Alarm  LSL601.Alarm  \\\n",
            "0            1            1            1      Inactive      Inactive   \n",
            "1            1            1            1      Inactive      Inactive   \n",
            "2            1            1            1      Inactive      Inactive   \n",
            "3            1            1            1      Inactive      Inactive   \n",
            "4            1            1            1      Inactive      Inactive   \n",
            "\n",
            "   LSH602.Alarm  LSL602.Alarm  LSH603.Alarm  LSL603.Alarm  \n",
            "0        Active      Inactive      Inactive        Active  \n",
            "1        Active      Inactive      Inactive        Active  \n",
            "2        Active      Inactive      Inactive        Active  \n",
            "3        Active      Inactive      Inactive        Active  \n",
            "4        Active      Inactive      Inactive        Active  \n",
            "\n",
            "[5 rows x 82 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:06<00:00, 71.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.1896652605421924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:06<00:00, 64.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Loss: 0.08038920870793356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:05<00:00, 76.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Loss: 0.06093308711445212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:07<00:00, 58.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 0.05263092267619475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:05<00:00, 76.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Loss: 0.050485544326717244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:07<00:00, 60.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Loss: 0.04442606939268371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:06<00:00, 71.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Loss: 0.04250088574796218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:06<00:00, 67.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Loss: 0.04097721933020084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:06<00:00, 65.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 0.0393116461872258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:06<00:00, 71.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 0.03729541370757173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 449/449 [00:01<00:00, 230.50it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anomalies detected: 527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zQobzdAjJz3E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}